{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adm_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq3WzRVyv2Lj",
        "outputId": "563c5a29-ade2-4d41-ed1b-21c0848c7d2c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b38T-a4IwYdV"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/ADM/HW5/\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MorDmeso4WSB"
      },
      "source": [
        "import networkx as nx\n",
        "from tqdm import tqdm\n",
        "import datetime"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWXQ9DEdZWws"
      },
      "source": [
        "##EXPLORE THE DATASET AND FIND MAXIMUM AND MINIMUM TIMESTAMPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytsmDY-7vAfa"
      },
      "source": [
        "def read_data(file,max,min):\n",
        "  for line in tqdm(file):\n",
        "    \n",
        "    #Read the line\n",
        "    splitted_line=line.split(\" \")\n",
        "    interaction_time=int(splitted_line[2])\n",
        "    if interaction_time > max:\n",
        "      max=interaction_time\n",
        "    if interaction_time < min:\n",
        "      min=interaction_time\n",
        "  return(max,min)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_kOGn5gZWwt",
        "outputId": "1b879f6c-22a8-4fde-82a3-c278f7ccd181"
      },
      "source": [
        "#Open dataset files\n",
        "a2q=open(\"a2q.txt\")\n",
        "c2a=open(\"c2a.txt\")\n",
        "c2q=open(\"c2q.txt\")\n",
        "\n",
        "#Define maximum and minimum seen timestamp (1647265600 correspond to March 2022) \n",
        "max=0\n",
        "min=1647265600\n",
        "\n",
        "#Read maximum and minimum timestamps on top of 3 dataset files\n",
        "max,min=read_data(a2q,max,min)\n",
        "max,min=read_data(c2a,max,min)\n",
        "max,min=read_data(c2q,max,min)\n",
        "\n",
        "#Close dataset files\n",
        "a2q.close()\n",
        "c2a.close()\n",
        "c2q.close()\n",
        "\n",
        "print(\"\\nMaximum seen timestamp is:\",datetime.datetime.fromtimestamp(max).strftime(\"%Y-%m-%d\"),sep=\" \")\n",
        "print(\"\\nMinimum seen timestamp is:\",datetime.datetime.fromtimestamp(min).strftime(\"%Y-%m-%d\"),sep=\" \")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17823525it [00:16, 1093123.42it/s]\n",
            "25405374it [00:23, 1075943.82it/s]\n",
            "20268151it [00:18, 1070025.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Maximum seen timestamp is: 2016-03-06\n",
            "\n",
            "Minimum seen timestamp is: 2008-08-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJwOSml35Y7Y"
      },
      "source": [
        "#Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRDpgBhAHWxL"
      },
      "source": [
        "def create_graph_layer(G,file_type,file_name,include_self_loops,time_interval):\n",
        "  \n",
        "  for line in tqdm(file_type):\n",
        "    \n",
        "    #Read the line\n",
        "    splitted_line=line.split(\" \")\n",
        "    #Extract source node,destination node and interaction time\n",
        "    source_node=int(splitted_line[0])\n",
        "    destination_node=int(splitted_line[1])\n",
        "    #interaction_time=int(int(splitted_line[2])/3600)\n",
        "    #Convert unix timestamp into datetime format\n",
        "    interaction_time=datetime.datetime.fromtimestamp(int(splitted_line[2])).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    #Disregard self loops if required and take only first maximum_time hours of the dataset\n",
        "    if ((source_node!=destination_node) or include_self_loops) and time_interval[0] < interaction_time<time_interval[1]:\n",
        "      \n",
        "      #If G has already an edge, increase its weight and update the interaction time\n",
        "      if G.has_edge(source_node,destination_node) and file_name in G[source_node][destination_node]:\n",
        "        G[source_node][destination_node][file_name][file_name]=1/(1/G[source_node][destination_node][file_name][file_name]+1)\n",
        "        G[source_node][destination_node][file_name][\"time\"].append(interaction_time)\n",
        "      \n",
        "      #If that edge is noy yet existing, initialize its type and value depending on the file we are reading\n",
        "      else:\n",
        "        if file_name==\"a2q\":\n",
        "          G.add_edge(source_node, destination_node,key=file_name, a2q=1,time=[interaction_time])\n",
        "        if file_name==\"c2q\":\n",
        "          G.add_edge(source_node, destination_node,key=file_name, c2q=1,time=[interaction_time])\n",
        "        if file_name==\"c2a\":\n",
        "          G.add_edge(source_node, destination_node,key=file_name, c2a=1,time=[interaction_time])\n",
        "  return(G)\n",
        "\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WsWqE9XCQ0A",
        "outputId": "b2e083b3-5af8-4a8c-9c46-4e2bf9bb2120"
      },
      "source": [
        "#Open dataset files\n",
        "a2q=open(\"a2q.txt\")\n",
        "c2a=open(\"c2a.txt\")\n",
        "c2q=open(\"c2q.txt\")\n",
        "\n",
        "\n",
        "#Create multidirected graph\n",
        "G = nx.MultiDiGraph()\n",
        "G=create_graph_layer(G,c2a,\"c2a\",include_self_loops=False,time_interval=[\"2015-01-01\", \"2016-03-01\"])\n",
        "G=create_graph_layer(G,a2q,\"a2q\",include_self_loops=False,time_interval=[\"2015-01-01\", \"2016-03-01\"])\n",
        "G=create_graph_layer(G,c2q,\"c2q\",include_self_loops=False,time_interval=[\"2015-01-01\", \"2016-03-01\"])\n",
        "\n",
        "#Close dataset files\n",
        "a2q.close()\n",
        "c2a.close()\n",
        "c2q.close()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25405374it [02:55, 144456.13it/s]\n",
            "17823525it [02:14, 132874.93it/s]\n",
            "20268151it [02:38, 128008.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOxKSwTBW8JC"
      },
      "source": [
        "#For the construction of the functionality 1, the graph will be considered unweighted\n",
        "def functionality_1(G,graph_type):\n",
        "\n",
        "  #Define auxiliary variables to store the number of users,\n",
        "  #of total interactions, of average interactions, connected flag,\n",
        "  #and graph density value. Unique_nodes is initialized as set\n",
        "  #Since we don't want to count the same user in the graph twice\n",
        "  unique_nodes=set([])\n",
        "  total_interactions=0\n",
        "  average_interactions=0\n",
        "  undirected=\"True\"\n",
        "  graph_density=0\n",
        "\n",
        "  #For every edge in our graph:\n",
        "  for edge in list(G.edges(data=True)):\n",
        "    \n",
        "    #Identify source and destination node + the attributes of the edge\n",
        "    source_node=edge[0]\n",
        "    destination_node=edge[1]\n",
        "    attributes =edge[2]\n",
        "\n",
        "    #If the edge is of the kind inputted by the user inside the functionality:\n",
        "    #(it basically mean we will work only on 1 of the 3 different graphs) \n",
        "    if graph_type in attributes:\n",
        "      \n",
        "      #If there is an edge of the same type joining both (source node, destination node)\n",
        "      #and (destination node, source node), that edge is considered as undirected. If so\n",
        "      #doesn't happen, the directed flag is set to false and the directed flag is not runned\n",
        "      #for the next edges (as we already understood the graph isn't  undirected)\n",
        "      if (undirected==\"True\") and (source_node in G[destination_node]) and (graph_type in G[destination_node][source_node]):\n",
        "        undirected=\"True\"\n",
        "      else:\n",
        "        undirected=\"False\"  \n",
        "      \n",
        "      #Append source and destination node to the unique node set\n",
        "      unique_nodes.update([source_node,destination_node])\n",
        "      \n",
        "      #Increase the value of the total interactions\n",
        "      #total_interactions+=1/attributes.get(\"a2q\")\n",
        "      total_interactions+=1\n",
        "\n",
        "  #Compute the number of users as the cardinality of the unique_nodes set\n",
        "  n_users=len(unique_nodes)\n",
        "\n",
        "  #If more than one user if found, compute graph density and average number of interactions\n",
        "  if n_users>0:\n",
        "    average_interactions=total_interactions/n_users\n",
        "    graph_density=total_interactions/(n_users*(n_users-1))\n",
        "\n",
        "  return(undirected,n_users,total_interactions,average_interactions,graph_density)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMWBG7DWjr7t"
      },
      "source": [
        "#Compute outputs from functionality 1\n",
        "undirected,n_users,total_interactions,average_interactions,graph_density=functionality_1(G,graph_type=\"c2a\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4sTVBzyr_kY",
        "outputId": "3fdcb593-b2e0-44ab-aac9-cc0263b759f5"
      },
      "source": [
        "#Print output from functionality 1\n",
        "print(\"Unirected:\",undirected,\"\\nNumber of users:\",n_users,\n",
        "      \"\\nTotal interactions:\",total_interactions,\n",
        "      \"\\nAverage interactions per user\",round(average_interactions,5),\"\\nGraph density\",graph_density,sep=\" \")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unirected: False \n",
            "Number of users: 778496 \n",
            "Total interactions: 2408848 \n",
            "Average interactions per user 3.09423 \n",
            "Graph density 3.9746343683280205e-06\n"
          ]
        }
      ]
    }
  ]
}